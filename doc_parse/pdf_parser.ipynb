{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To achieve the tasks of parsing and analyzing EPUB and PDF documents, including extracting the table of contents, identifying sections, analyzing structure, and mapping relationships, here are the best approaches:\n",
    "\n",
    "## **Document Parser**\n",
    "### **PDF/EPUB Parsing**\n",
    "1. **LangChain Library**:\n",
    "   - Use LangChain's `EPUBLoader` for EPUB files and `PyMuPDF` or other loaders for PDFs. These tools split documents into sections or pages with associated metadata.\n",
    "   - Example for EPUB:\n",
    "     ```python\n",
    "     from langchain.document_loaders import EPUBLoader\n",
    "     loader = EPUBLoader(\"example_data/book.epub\")\n",
    "     documents = loader.load_and_split()\n",
    "     print(documents.content)\n",
    "     ```\n",
    "   - Example for PDF:\n",
    "     ```python\n",
    "     from langchain.document_loaders import PyMuPDF\n",
    "     loader = PyMuPDF(\"example_data/document.pdf\")\n",
    "     pages = loader.load_and_split()\n",
    "     print(pages.page_content)\n",
    "     ```\n",
    "  [1]\n",
    "\n",
    "2. **Aspose.PDF**:\n",
    "   - Aspose provides an online tool for parsing EPUB and PDF files to extract text, images, or other content quickly and securely[6].\n",
    "\n",
    "### **Table of Contents Extraction**\n",
    "1. **GroupDocs.Parser**:\n",
    "   - For EPUB files, use the `GetToc` method to extract a collection of `TocItem` objects representing the table of contents.\n",
    "\n",
    "2. **Huridocs PDF TOC Extractor**:\n",
    "   - For PDFs, this Docker-powered service extracts TOC information using document layout analysis.\n",
    "   - Example command:\n",
    "     ```bash\n",
    "     curl -X POST -F 'file=@/PATH/TO/PDF/pdf_name.pdf' localhost:5060/toc\n",
    "     ```\n",
    "  [7]\n",
    "\n",
    "### **Section Identification**\n",
    "- LangChain's splitting capabilities can help identify sections based on metadata or content structure[1].\n",
    "- For more advanced needs, consider using natural language processing (NLP) libraries like spaCy or NLTK to detect section headers and classify content.\n",
    "\n",
    "## **Structure Analyzer**\n",
    "### **Heading Hierarchy Analysis**\n",
    "- Tools like Thruuu's Heading Extractor can analyze heading structures (H1, H2, H3) in documents or web pages for hierarchical relationships[4].\n",
    "- Alternatively, use custom parsers to extract heading tags programmatically in structured formats.\n",
    "\n",
    "### **Chapter Relationship Mapping**\n",
    "- Utilize relationship mapping tools like DemandFarm or ClickUp to visualize chapter connections and hierarchies. These tools allow you to create organizational maps and analyze relationships between document segments[5].\n",
    "\n",
    "### **Key Sections Identification**\n",
    "- Use NLP techniques to identify key sections based on keywords or semantic similarity. Libraries like spaCy can assist in extracting specific sections such as introductions, conclusions, or summaries.\n",
    "\n",
    "## Recommended Workflow\n",
    "1. Parse the document using LangChain or Aspose tools.\n",
    "2. Extract the table of contents with GroupDocs.Parser (EPUB) or Huridocs (PDF).\n",
    "3. Analyze headings and structure using a heading extractor tool or custom NLP scripts.\n",
    "4. Map relationships between chapters using tools like DemandFarm for visual representation."
   ],
   "id": "b39f3d5334ee5bac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T10:39:31.551488Z",
     "start_time": "2025-02-06T10:38:47.020856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "  'deepseek-r1:7b',\n",
    "  messages=[{'role': 'user', 'content': 'What is 10 + 10?'}]\n",
    ")"
   ],
   "id": "d8869aa07dc87537",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T10:39:31.651206Z",
     "start_time": "2025-02-06T10:39:31.622225Z"
    }
   },
   "cell_type": "code",
   "source": "response",
   "id": "60904c7a82279226",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(model='deepseek-r1:7b', created_at='2025-02-06T10:39:31.476106Z', done=True, done_reason='stop', total_duration=44414674583, load_duration=1103883083, prompt_eval_count=13, prompt_eval_duration=8527000000, eval_count=132, eval_duration=34779000000, message=Message(role='assistant', content='<think>\\nI start by identifying the two numbers in the problem, which are both 10.\\n\\nNext, I add these two numbers together to find their sum.\\n\\nFinally, I calculate that 10 plus 10 equals 20.\\n</think>\\n\\n**Solution:**\\n\\nWe need to compute \\\\(10 + 10\\\\).\\n\\n1. **Identify the Numbers:**  \\n   The two numbers are both 10.\\n\\n2. **Addition:**  \\n   \\\\[\\n   10 + 10 = 20\\n   \\\\]\\n\\nTherefore, the final answer is:\\n\\n\\\\[\\n\\\\boxed{20}\\n\\\\]', images=None, tool_calls=None))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "978b1371e1bb91b6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
